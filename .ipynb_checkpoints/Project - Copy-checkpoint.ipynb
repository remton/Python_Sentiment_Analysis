{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21c45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn\n",
    "#pip install pandas\n",
    "\n",
    "# Main imports pandas and sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# We need to do some web scraping to get the review text\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Other imports\n",
    "import time\n",
    "import sys\n",
    "from os import system\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a83bc",
   "metadata": {},
   "source": [
    "# Load in data\n",
    "### There are a few steps to getting clean data\n",
    "- Read data from kaggle into dataframes\n",
    "- Get rid of unecessary features of the data\n",
    "- (For general data) get the review text from the web\n",
    "- Clean data using dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe1d14",
   "metadata": {},
   "source": [
    "## Read in data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257f8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets define our file paths for reading in data\n",
    "# download dataset at: https://www.kaggle.com/datasets/joyshil0599/multi-decade-video-game-review-dataset\n",
    "GENERAL_DATASET_PATH = \"data/general_reviews.csv\"\n",
    "# download dataset at: https://www.kaggle.com/datasets/noahx1/elden-ring-steam-reviews\n",
    "ELDEN_RING_DATASET_PATH = \"data/elden_ring_steam_reviews.csv\"\n",
    "# Path to save cleaned general data file\n",
    "GENERAL_CLEAN_DATA_PATH = 'data/general_data_clean.csv'\n",
    "\n",
    "#load in dataset\n",
    "# We have two datasets:\n",
    "# one using gamespot reviews (general_data)\n",
    "# the other Elden Ring Steam reviews (elden_ring_data)\n",
    "general_data = pd.read_csv(GENERAL_DATASET_PATH)\n",
    "elden_ring_data = pd.read_csv(ELDEN_RING_DATASET_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fd8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets only keep the columns we want\n",
    "general_data = general_data[['Review link','Rating/10']]\n",
    "elden_ring_data = elden_ring_data[['voted_up','review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020279b7",
   "metadata": {},
   "source": [
    "# Read in reviews from web (for general data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ae9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets define how to get the text of the reviews from the web\n",
    "def GetReviewsFromWeb():\n",
    "    num_processed = 1\n",
    "    prev_time = time.time()\n",
    "    num_links = len(general_data.index)\n",
    "    check_interval = 5\n",
    "    reviews = []\n",
    "    failed_links = []\n",
    "    for link in general_data['Review link']:\n",
    "        # Try to get the review text\n",
    "        try:\n",
    "            page = urllib.request.urlopen(link).read()\n",
    "            page = BeautifulSoup(page)\n",
    "            review = \"\"\n",
    "            body = page.find(class_=\"article-body typography-format\")\n",
    "            paragraphs = body.find_all(\"p\")\n",
    "            if(len(paragraphs)==0):\n",
    "                raise Exception('NO REVIEW TEXT FOUND')\n",
    "            for p in paragraphs:\n",
    "                review+=p.text+\" \"\n",
    "            reviews.append(review)\n",
    "        # If we could not get the review text\n",
    "        except:\n",
    "            reviews.append(None)\n",
    "            failed_links.append(link)\n",
    "        # Display progress\n",
    "        num_processed = num_processed + 1\n",
    "        if(num_processed % check_interval == 0):\n",
    "            prediction = (time.time() - prev_time)/(check_interval) * (num_links-len(reviews))\n",
    "            prev_time = time.time()\n",
    "            system('cls')\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Reviews lost: {len(failed_links)}\")\n",
    "            print(f\"processed: {num_processed} / {num_links}\")\n",
    "            print(f\"Time left: {int(prediction)} s\")  \n",
    "    #Update dataframe and write to file\n",
    "    general_data['Review'] = reviews\n",
    "    # Now lets finish cleaning the data by dropping any rows where we do not have a review\n",
    "    old_size = general_data.shape\n",
    "    general_data.dropna(inplace=True)\n",
    "    general_data.to_csv(GENERAL_CLEAN_DATA_PATH)\n",
    "    new_size = general_data.shape\n",
    "    print(\"Dropping invalid reviews.\")\n",
    "    print(f\"Old count: {old_size[0]}\")\n",
    "    print(f\"New count: {new_size[0]}\")\n",
    "    print(f\"Removed {old_size[0]-new_size[0]} reviews.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "001e240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we don't already have the clean data we need to get it from the web\n",
    "file_found = True\n",
    "try:\n",
    "    general_data = pd.read_csv(GENERAL_CLEAN_DATA_PATH)\n",
    "except FileNotFoundError as e:\n",
    "    file_found = False\n",
    "if(not file_found):\n",
    "    GetReviewsFromWeb()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e531b6a",
   "metadata": {},
   "source": [
    "# Now lets define our classifications (Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c89124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define 2 sentiments to classify\n",
    "GOOD = 'Good'\n",
    "BAD = 'Bad'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10eb26a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA DISTRIBUTION:\n",
      "Bad: 487\n",
      "Good: 1160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review link</th>\n",
       "      <th>Rating/10</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.gamespot.com/reviews/tales-of-symp...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bad</td>\n",
       "      <td>Tales of Symphonia was a formative experience ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.gamespot.com/reviews/kirbys-return...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>Mario is the most versatile character in the N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.gamespot.com/reviews/hogwarts-lega...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Bad</td>\n",
       "      <td>It's difficult to find someone oblivious to th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.gamespot.com/reviews/atomic-heart-...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Bad</td>\n",
       "      <td>In the alternate history of Atomic Heart, a sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.gamespot.com/reviews/like-a-dragon...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Good</td>\n",
       "      <td>Take the faces, voices, and over-the-top theat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Review link  Rating/10 Sentiment   \n",
       "0  https://www.gamespot.com/reviews/tales-of-symp...        5.0       Bad  \\\n",
       "1  https://www.gamespot.com/reviews/kirbys-return...        7.0      Good   \n",
       "2  https://www.gamespot.com/reviews/hogwarts-lega...        6.0       Bad   \n",
       "3  https://www.gamespot.com/reviews/atomic-heart-...        6.0       Bad   \n",
       "4  https://www.gamespot.com/reviews/like-a-dragon...        8.0      Good   \n",
       "\n",
       "                                              Review  \n",
       "0  Tales of Symphonia was a formative experience ...  \n",
       "1  Mario is the most versatile character in the N...  \n",
       "2  It's difficult to find someone oblivious to th...  \n",
       "3  In the alternate history of Atomic Heart, a sc...  \n",
       "4  Take the faces, voices, and over-the-top theat...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# General data\n",
    "# I tried to choose values for rating that made sense and split the data kind of evenly\n",
    "def GetSentimentFromRating(rating):\n",
    "    if(rating is None):\n",
    "        return None\n",
    "    if(rating >= 7):\n",
    "        return GOOD\n",
    "    if(rating > 0):\n",
    "        return BAD\n",
    "s = []\n",
    "for rating in general_data['Rating/10'].to_list():\n",
    "    s.append(GetSentimentFromRating(rating))\n",
    "general_data['Sentiment'] = s\n",
    "general_data.dropna(inplace=True)\n",
    "print(\"DATA DISTRIBUTION:\")\n",
    "SENTIMENTS = general_data['Sentiment'].unique()\n",
    "for s in SENTIMENTS:\n",
    "    print(f\"{s}: {sum(1 for i in general_data['Sentiment'] if i == s)}\")\n",
    "general_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d093527e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA DISTRIBUTION:\n",
      "Good: 9174\n",
      "Bad: 591\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>voted_up</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>being killed over and over again is fun</td>\n",
       "      <td>True</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I write this review as I have 100% completed E...</td>\n",
       "      <td>True</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fun</td>\n",
       "      <td>True</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pretty cool.</td>\n",
       "      <td>True</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AMAZINGGGGGGGGGGGGG</td>\n",
       "      <td>True</td>\n",
       "      <td>Good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  voted_up Sentiment\n",
       "0            being killed over and over again is fun      True      Good\n",
       "1  I write this review as I have 100% completed E...      True      Good\n",
       "2                                                Fun      True      Good\n",
       "3                                       pretty cool.      True      Good\n",
       "4                                AMAZINGGGGGGGGGGGGG      True      Good"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#elden ring data\n",
    "elden_ring_data = elden_ring_data[['review','voted_up']]\n",
    "elden_ring_data.rename(columns={'review':'Review'},inplace=True)\n",
    "def GetSentimentFromUpVote(up_vote):\n",
    "    if(up_vote):\n",
    "        return GOOD\n",
    "    else:\n",
    "        return BAD\n",
    "s = []\n",
    "for upvote in elden_ring_data['voted_up'].to_list():\n",
    "    s.append(GetSentimentFromUpVote(upvote))\n",
    "elden_ring_data['Sentiment'] = s\n",
    "elden_ring_data.dropna(inplace=True)\n",
    "print(\"DATA DISTRIBUTION:\")\n",
    "SENTIMENTS = elden_ring_data['Sentiment'].unique()\n",
    "for s in SENTIMENTS:\n",
    "    print(f\"{s}: {sum(1 for i in elden_ring_data['Sentiment'] if i == s)}\")\n",
    "elden_ring_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c567b",
   "metadata": {},
   "source": [
    "# Creating svm\n",
    "#### Helpful link to understand how this works:\n",
    "- https://medium.com/@vasista/sentiment-analysis-using-svm-338d418e3ff1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c25c7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitData(df,test_split=0.3):\n",
    "    #split datasets\n",
    "    X = df['Review']\n",
    "    y = df['Sentiment'] \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_split, random_state=1) \n",
    "    X_train.to_list()\n",
    "    X_test = X_test.to_list()\n",
    "    y_train = y_train.to_list()\n",
    "    y_test = y_test.to_list()\n",
    "    return X, y, X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c62874",
   "metadata": {},
   "source": [
    "## Vectorize the data\n",
    "We will be using a method called **Term Frequency and Inverse Document Frequency (TF-IDF)**. \n",
    "Here is how it works: https://medium.com/@vasista/preparing-the-text-data-with-scikit-learn-b31a3df567e\n",
    "\n",
    "#### sklearn supplies an easy way to implement this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d96ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vectorize(X_train,X_test):\n",
    "    # Create feature vectors\n",
    "    vectorizer = TfidfVectorizer(min_df = 5,max_df = 0.8,sublinear_tf = True,use_idf = True)\n",
    "    train_vectors = vectorizer.fit_transform(X_train)\n",
    "    test_vectors = vectorizer.transform(X_test)\n",
    "    return train_vectors, test_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4c3fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestSVM(svm_linear, test_vectors, y_test):\n",
    "    # Test SVM\n",
    "    print('Testing SVM ...')\n",
    "    start_time = time.time()\n",
    "    prediction = svm_linear.predict(test_vectors)\n",
    "    end_time = time.time()\n",
    "    print(f\"Tested SVM in {end_time-start_time} s\")\n",
    "    report = classification_report(y_test, prediction,output_dict=True,zero_division=0)\n",
    "    for key in report.keys():\n",
    "        print(f'{key}: {report[key]}\\n')\n",
    "        return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fdb86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateSVM(train_vectors, y_train):\n",
    "    # Create and train SVM\n",
    "    svm_linear = svm.SVC(kernel='linear')\n",
    "    print('training SVM...')\n",
    "    start_time = time.time()\n",
    "    svm_linear.fit(train_vectors, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Trained SVM in {end_time-start_time} s\")\n",
    "    return svm_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55cde9",
   "metadata": {},
   "source": [
    "# Train SVM with general data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aed9db82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training SVM...\n",
      "Trained SVM in 4.045910120010376 s\n"
     ]
    }
   ],
   "source": [
    "general_X, general_Y, general_X_train, general_X_test, general_y_train, general_y_test = SplitData(general_data)\n",
    "general_train_vectors, general_test_vectors = Vectorize(general_X_train, general_X_test)\n",
    "general_svm = CreateSVM(general_train_vectors, general_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ec4b6",
   "metadata": {},
   "source": [
    "# Test general_svm on general test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f690fa2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing SVM ...\n",
      "Tested SVM in 1.5386075973510742 s\n",
      "Bad: {'precision': 0.8703703703703703, 'recall': 0.3032258064516129, 'f1-score': 0.44976076555023925, 'support': 155}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Bad': {'precision': 0.8703703703703703,\n",
       "  'recall': 0.3032258064516129,\n",
       "  'f1-score': 0.44976076555023925,\n",
       "  'support': 155},\n",
       " 'Good': {'precision': 0.7551020408163265,\n",
       "  'recall': 0.9794117647058823,\n",
       "  'f1-score': 0.8527528809218949,\n",
       "  'support': 340},\n",
       " 'accuracy': 0.7676767676767676,\n",
       " 'macro avg': {'precision': 0.8127362055933485,\n",
       "  'recall': 0.6413187855787477,\n",
       "  'f1-score': 0.6512568232360672,\n",
       "  'support': 495},\n",
       " 'weighted avg': {'precision': 0.7911961642120372,\n",
       "  'recall': 0.7676767676767676,\n",
       "  'f1-score': 0.7265634306540028,\n",
       "  'support': 495}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestSVM(general_svm, general_test_vectors, general_y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
