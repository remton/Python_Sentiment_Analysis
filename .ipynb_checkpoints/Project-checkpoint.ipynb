{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21c45e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn\n",
    "#pip install pandas\n",
    "\n",
    "# Main imports pandas and sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "# We may need to do some web scraping to get the review text\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Other imports\n",
    "import time\n",
    "import sys\n",
    "from os import system\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021a83bc",
   "metadata": {},
   "source": [
    "# Load in data\n",
    "### There are a few steps to getting clean data\n",
    "- Read data from kaggle into dataframes\n",
    "- Get rid of unecessary features of the data\n",
    "- (For game spot data) get the review text from the web\n",
    "- Clean data using dropna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfe1d14",
   "metadata": {},
   "source": [
    "## Read in data from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257f8be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download dataset at: https://www.kaggle.com/datasets/joyshil0599/multi-decade-video-game-review-dataset\n",
    "GAME_SPOT_DATASET_PATH = \"data/game_spot_data.csv\"\n",
    "# downoad dataset at: https://www.kaggle.com/datasets/andrewmvd/steam-reviews\n",
    "STEAM_DATASET_PATH = 'data/steam_data.csv'\n",
    "# download dataset at: https://www.kaggle.com/datasets/noahx1/elden-ring-steam-reviews\n",
    "ELDEN_RING_DATASET_PATH = \"data/elden_ring_data.csv\"\n",
    "\n",
    "# Read in the datasets\n",
    "game_spot_data = pd.read_csv(GAME_SPOT_DATASET_PATH)\n",
    "steam_data = pd.read_csv(STEAM_DATASET_PATH)\n",
    "elden_ring_data = pd.read_csv(ELDEN_RING_DATASET_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5fd8eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets only keep the columns we want\n",
    "game_spot_cols = ['Review link','Rating/10']\n",
    "if('Review' in game_spot_data.columns):\n",
    "    game_spot_cols.append('Review')\n",
    "steam_cols = ['review_text','review_score']\n",
    "elden_ring_cols = ['voted_up','review']\n",
    "\n",
    "game_spot_data = game_spot_data[game_spot_cols]\n",
    "steam_data = steam_data[steam_cols]\n",
    "elden_ring_data = elden_ring_data[elden_ring_cols]\n",
    "\n",
    "# Lets rename some columns and change them to be consistant\n",
    "steam_data['review_score'].replace({1:True,-1:False},inplace=True)\n",
    "steam_data.rename(columns={'review_score':'up_vote','review_text':'Review'}, inplace=True)\n",
    "elden_ring_data.rename(columns={'voted_up':'up_vote','review':'Review'},inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020279b7",
   "metadata": {},
   "source": [
    "# Read in reviews from web (for game spot data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70ae9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets define how to get the text of the reviews from the web\n",
    "import multiprocessing as mp\n",
    "\n",
    "def ScrapeSingle(link): \n",
    "    try:\n",
    "        page = urllib.request.urlopen(link).read()\n",
    "        page = BeautifulSoup(page)\n",
    "        review = \"\"\n",
    "        body = page.find(class_=\"article-body typography-format\")\n",
    "        paragraphs = body.find_all(\"p\")\n",
    "        if(len(paragraphs)==0):\n",
    "            raise Exception('NO REVIEW TEXT FOUND')\n",
    "        for p in paragraphs:\n",
    "            review+=p.text+\" \"\n",
    "        return review\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "        \n",
    "def GetReviewsFromWebParallel(num_processes=16):\n",
    "    num_processed = 1\n",
    "    prev_time = time.time()\n",
    "    check_interval = 5    \n",
    "    num_links = len(game_spot_data.index)\n",
    "    pool = mp.Pool(processes=num_processes)\n",
    "    results = pool.map(ScrapeSingle, game_spot_data['Review link'])\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    reviews = []\n",
    "    failed_links = []\n",
    "    for r, link in zip(results, game_spot_data['Review link']):\n",
    "        if r is None:\n",
    "               # Display progress\n",
    "        num_processed = num_processed + 1\n",
    "        if(num_processed % check_interval == 0):\n",
    "            prediction = (time.time() - prev_time)/(check_interval) * (num_links-len(reviews))\n",
    "            prev_time = time.time()\n",
    "            system('cls')\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Reviews lost: {len(failed_links)}\")\n",
    "            print(f\"processed: {num_processed} / {num_links}\")\n",
    "            print(f\"Time left: {int(prediction)} s\")  \n",
    "            reviews.append(None)\n",
    "            failed_links.append(link)\n",
    "        else:\n",
    "            reviews.append(r)  \n",
    "    game_spot_data['Review'] = reviews\n",
    "        \n",
    "def GetReviewsFromWeb():\n",
    "    num_processed = 1\n",
    "    prev_time = time.time()\n",
    "    num_links = len(game_spot_data.index)\n",
    "    check_interval = 5\n",
    "    reviews = []\n",
    "    failed_links = []\n",
    "    for link in game_spot_data['Review link']:\n",
    "        # Try to get the review text\n",
    "        try:\n",
    "            page = urllib.request.urlopen(link).read()\n",
    "            page = BeautifulSoup(page)\n",
    "            review = \"\"\n",
    "            body = page.find(class_=\"article-body typography-format\")\n",
    "            paragraphs = body.find_all(\"p\")\n",
    "            if(len(paragraphs)==0):\n",
    "                raise Exception('NO REVIEW TEXT FOUND')\n",
    "            for p in paragraphs:\n",
    "                review+=p.text+\" \"\n",
    "            reviews.append(review)\n",
    "        # If we could not get the review text\n",
    "        except:\n",
    "            reviews.append(None)\n",
    "            failed_links.append(link)\n",
    "        # Display progress\n",
    "        num_processed = num_processed + 1\n",
    "        if(num_processed % check_interval == 0):\n",
    "            prediction = (time.time() - prev_time)/(check_interval) * (num_links-len(reviews))\n",
    "            prev_time = time.time()\n",
    "            system('cls')\n",
    "            clear_output(wait=True)\n",
    "            print(f\"Reviews lost: {len(failed_links)}\")\n",
    "            print(f\"processed: {num_processed} / {num_links}\")\n",
    "            print(f\"Time left: {int(prediction)} s\")  \n",
    "    # Update dataframe and write to file\n",
    "    game_spot_data['Review'] = reviews\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If gamespot data does not have review then we need to get it from the web\n",
    "if(not 'Review' in game_spot_data.columns):\n",
    "    GetReviewsFromWebParallel()\n",
    "    game_spot_data.to_csv(GAME_SPOT_DATASET_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e531b6a",
   "metadata": {},
   "source": [
    "# Now lets define our classifications (Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6c89124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define 2 sentiments to classify\n",
    "GOOD = 'Good'\n",
    "BAD = 'Bad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c4e923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSentimentFromRating(rating):\n",
    "    if(rating is None):\n",
    "        return None\n",
    "    if(rating > 7):\n",
    "        return GOOD\n",
    "    if(rating > 0):\n",
    "        return BAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2972cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSentimentFromUpVote(up_vote):\n",
    "    if(up_vote):\n",
    "        return GOOD\n",
    "    else:\n",
    "        return BAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acea0b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddSentiment(df):\n",
    "    s = []\n",
    "    if('Rating/10' in df.columns):\n",
    "        for rating in game_spot_data['Rating/10'].to_list():\n",
    "            s.append(GetSentimentFromRating(rating))\n",
    "    elif('up_vote' in df.columns):\n",
    "        for upvote in df['up_vote'].to_list():\n",
    "            s.append(GetSentimentFromUpVote(upvote))\n",
    "    else:\n",
    "        raise Exception(f\"No column in dataframe to use for sentiment! {df.columns}\")\n",
    "    df['Sentiment'] = s\n",
    "    print(\"DATA DISTRIBUTION:\")\n",
    "    SENTIMENTS = df['Sentiment'].unique()\n",
    "    for s in SENTIMENTS:\n",
    "        print(f\"{s}: {sum(1 for i in df['Sentiment'] if i == s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10eb26a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AddSentiment(game_spot_data)\n",
    "AddSentiment(steam_data)\n",
    "AddSentiment(elden_ring_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6731a3b",
   "metadata": {},
   "source": [
    "# Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ff05be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CleanData(df):\n",
    "    # Now lets finish cleaning the data by dropping any invalid rows\n",
    "    old_size = df.shape\n",
    "    df.dropna(inplace=True)\n",
    "    new_size = df.shape\n",
    "    print(\"Dropping rows\")\n",
    "    print(f\"Old count: {old_size[0]}\")\n",
    "    print(f\"New count: {new_size[0]}\")\n",
    "    print(f\"Removed {old_size[0]-new_size[0]} rows.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e926caed",
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanData(game_spot_data)\n",
    "CleanData(steam_data)\n",
    "CleanData(elden_ring_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d639f759",
   "metadata": {},
   "source": [
    "# Now we split our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25c7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SplitData(df,test_split=0.3):\n",
    "    #split datasets\n",
    "    X = df['Review']\n",
    "    y = df['Sentiment'] \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = test_split, random_state=1) \n",
    "    X_train.to_list()\n",
    "    X_test = X_test.to_list()\n",
    "    y_train = y_train.to_list()\n",
    "    y_test = y_test.to_list()\n",
    "    return X_train, X_test, y_train, y_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6897e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_spot_X_train, game_spot_X_test, game_spot_y_train, game_spot_y_test = SplitData(game_spot_data)\n",
    "steam_X_train, steam_X_test, steam_y_train, steam_y_test = SplitData(steam_data)\n",
    "elden_ring_X_train, elden_ring_X_test, elden_ring_y_train, elden_ring_y_test = SplitData(elden_ring_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c62874",
   "metadata": {},
   "source": [
    "## Vectorize the data\n",
    "We will be using a method called **Term Frequency and Inverse Document Frequency (TF-IDF)**. \n",
    "Here is how it works: https://medium.com/@vasista/preparing-the-text-data-with-scikit-learn-b31a3df567e\n",
    "\n",
    "#### sklearn supplies an easy way to implement this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d96ec3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateVectorizer(X_train):\n",
    "    vectorizer = TfidfVectorizer(min_df = 5,max_df = 0.8,sublinear_tf = True,use_idf = True)\n",
    "    train_vectors = vectorizer.fit_transform(X_train)\n",
    "    return vectorizer, train_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831c567b",
   "metadata": {},
   "source": [
    "# Creating svm\n",
    "#### Helpful link to understand how this works:\n",
    "- https://medium.com/@vasista/sentiment-analysis-using-svm-338d418e3ff1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c3fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestSVM(svm_linear, vectorizer, X_test, y_test): \n",
    "    print('Testing SVM ...')\n",
    "    start_time = time.time()\n",
    "    test_vectors = vectorizer.transform(X_test)\n",
    "    prediction = svm_linear.predict(test_vectors)\n",
    "    end_time = time.time()\n",
    "    print(f\"Tested SVM in {end_time-start_time} s\")\n",
    "    report = classification_report(y_test, prediction, output_dict=True, zero_division=0)\n",
    "    cm = confusion_matrix(y_test, prediction)\n",
    "    cm_disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels = svm_linear.classes_)\n",
    "    cm_disp.plot()\n",
    "    for key in report.keys():\n",
    "        print(f'{key}: {report[key]}\\n')\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb86ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CreateSVM(x_train, y_train):\n",
    "    print('training SVM...')\n",
    "    start_time = time.time()\n",
    "    vectorizer, train_vectors = CreateVectorizer(x_train)\n",
    "    svm_linear = svm.LinearSVC()\n",
    "    start_time = time.time()\n",
    "    svm_linear.fit(train_vectors, y_train)\n",
    "    end_time = time.time()\n",
    "    print(f\"Trained SVM in {end_time-start_time} s\")\n",
    "    return svm_linear, vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b55cde9",
   "metadata": {},
   "source": [
    "# Train SVM with game spot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed9db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_spot_svm, game_spot_vectorizer = CreateSVM(game_spot_X_train, game_spot_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040ec4b6",
   "metadata": {},
   "source": [
    "### Test game_spot_svm on game_spot test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f690fa2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = TestSVM(game_spot_svm, game_spot_vectorizer, game_spot_X_test, game_spot_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a25e178",
   "metadata": {},
   "source": [
    "### Test game_spot_svm on steam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4328dce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "report = TestSVM(game_spot_svm, game_spot_vectorizer, steam_X_test, steam_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "417e6031",
   "metadata": {},
   "source": [
    "### Test game_spot_svm on elden ring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491760fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = TestSVM(game_spot_svm, game_spot_vectorizer, elden_ring_X_test, elden_ring_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcddbb2",
   "metadata": {},
   "source": [
    "# Train SVM with elden ring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8376ceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "elden_ring_svm, elden_ring_vectorizer = CreateSVM(elden_ring_X_train, elden_ring_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c8f02c",
   "metadata": {},
   "source": [
    "### Test elden_ring_svm on elden ring test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d542c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = TestSVM(elden_ring_svm, elden_ring_vectorizer, elden_ring_X_test, elden_ring_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd49d6",
   "metadata": {},
   "source": [
    "### Test elden_ring_svm on steam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbd5613",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = TestSVM(elden_ring_svm, elden_ring_vectorizer, steam_X_test, steam_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efe33c5",
   "metadata": {},
   "source": [
    "### Test elden_ring_svm on game spot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0608c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = TestSVM(elden_ring_svm, elden_ring_vectorizer, game_spot_X_test, game_spot_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4eb063c",
   "metadata": {},
   "source": [
    "# Train SVM with Steam Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd6c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "steam_svm, steam_vectorizer = CreateSVM(steam_X_train, steam_y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9639fcc8",
   "metadata": {},
   "source": [
    "### Test steam_svm on steam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c22a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = TestSVM(steam_svm, steam_vectorizer, steam_X_test, steam_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "950b7255",
   "metadata": {},
   "source": [
    "### Test steam_svm on game spot data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e28fc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = TestSVM(steam_svm, steam_vectorizer, game_spot_X_test, game_spot_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a84645",
   "metadata": {},
   "source": [
    "### Test steam_svm on elden ring data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f82ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = TestSVM(steam_svm, steam_vectorizer, elden_ring_X_test, elden_ring_y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05c74f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
